{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_programming_2022/blob/main/05_cnn_rnn/08_simple_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niaz8_W6OX34"
      },
      "source": [
        "# シンプルなRNNの実装\n",
        "PyTorchを使って、シンプルな再帰型ニューラルネットワーク（RNN）を実装します。  \n",
        "RNNにノイズ付きサインカーブを学習させて、1つ先の未来を予測することによる曲線の描画を行います。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoISGl864sy9"
      },
      "source": [
        "## 訓練用データの作成\n",
        "まずは、サインカーブに乱数でノイズを加えてRNNに用いる訓練用のデータを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ1S5UNy-rpY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sin_x = np.linspace(-2*np.pi, 2*np.pi)  # -2πから2πまで\n",
        "sin_y = np.sin(sin_x)  + 0.1*np.random.randn(len(sin_x))  # sin関数に乱数でノイズを加える\n",
        "plt.plot(sin_x, sin_y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyLBjYjr3RXu"
      },
      "source": [
        "このようなノイズ付きサインカーブの一部を切り取って入力の時系列とし、次の値を予測するようにRNNを訓練します。    \n",
        "sin波自体は単純な時系列データですが、このようなsin波をニューラルネットワークで学習することができれば、例えば音声認識などに応用することも可能です。  \n",
        "今回の扱う対象はシンプルですが、現実社会で広く応用が可能することができます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvRgf3-j2k76"
      },
      "source": [
        "## データの前処理\n",
        "入力、正解データをRNNに適した形に整えます。  \n",
        "時系列から次の値を予測できるように、時系列を入力として正解はその1つ後の値とします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFmq4Oy6apUC"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "n_time = 10  # 時系列の数\n",
        "n_sample = len(sin_x)-n_time  # サンプル数\n",
        "\n",
        "input_data = np.zeros((n_sample, n_time, 1))  # 入力\n",
        "correct_data = np.zeros((n_sample, 1))  # 正解\n",
        "for i in range(n_sample):\n",
        "    input_data[i] = sin_y[i:i+n_time].reshape(-1, 1)\n",
        "    correct_data[i] = sin_y[i+n_time:i+n_time+1]  # 正解は入力よりも一つ後\n",
        "\n",
        "input_data = torch.tensor(input_data, dtype=torch.float)  # テンソルに変換\n",
        "correct_data = torch.tensor(correct_data, dtype=torch.float)\n",
        "dataset = torch.utils.data.TensorDataset(input_data, correct_data)  # データセットの作成\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True)  # DataLoaderの設定"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FalXNYaJPkoE"
      },
      "source": [
        "## モデルの構築\n",
        "`nn.Module`モジュールを継承したクラスとして、モデルを構築します。  \n",
        "RNNは`nn.RNN`を使って実装することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuqqZmsh_jNK"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(  # RNN層\n",
        "            input_size=1,  # 入力サイズ\n",
        "            hidden_size=64,  # ニューロン数\n",
        "            batch_first=True,  # 入力を (バッチサイズ, 時系列の数, 入力の数) にする\n",
        "        )\n",
        "        self.fc = nn.Linear(64, 1)  # 全結合層\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_rnn, h = self.rnn(x, None)  # hは次の時刻に渡される値、 Noneでその初期値が0に\n",
        "        y = self.fc(y_rnn[:, -1, :])  # yは最後の時刻の出力\n",
        "        return y\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsW5zCKhQE9p"
      },
      "source": [
        "## 学習\n",
        "モデルを訓練します。  \n",
        "DataLoaderを使い、ミニバッチを取り出して訓練および評価を行います。  \n",
        "訓練したモデルを使い、直近の時系列を使った予測結果を次々と時系列に加えていくことにより、曲線が生成されます。  \n",
        "学習が進むとともに次第にサインカーブが生成されるようになりますが、曲線は一定のエポック間隔でグラフとして描画されます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6zwN3nArbGC"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# 平均二乗誤差関数\n",
        "loss_fnc = nn.MSELoss()\n",
        "\n",
        "# 最適化アルゴリズム\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)  # 学習率は0.01\n",
        "\n",
        "# 損失のログ\n",
        "record_loss_train = []\n",
        "\n",
        "# 学習\n",
        "for i in range(50):  # 50エポック学習\n",
        "    net.train()  # 訓練モード\n",
        "    loss_train = 0\n",
        "    for j, (x, t) in enumerate(train_loader):  # ミニバッチ（x, t）を取り出す\n",
        "        y = net(x)\n",
        "        loss = loss_fnc(y, t)\n",
        "        loss_train += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    loss_train /= j+1\n",
        "    record_loss_train.append(loss_train)\n",
        "\n",
        "    if i%2 == 0:\n",
        "        print(\"Epoch:\", i, \"Loss_Train:\", loss_train)\n",
        "        predicted = list(input_data[0].reshape(-1)) # 最初の入力\n",
        "        for i in range(n_sample):\n",
        "            x = torch.tensor(predicted[-n_time:])  # 直近の時系列を取り出す\n",
        "            x = x.reshape(1, n_time, 1)  # (バッチサイズ, 時系列の数, 入力の数)\n",
        "            y = net(x)\n",
        "            predicted.append(y[0].item())  # 予測結果をpredictedに追加する\n",
        "\n",
        "        plt.plot(range(len(sin_y)), sin_y, label=\"Correct\")\n",
        "        plt.plot(range(len(predicted)), predicted, label=\"Predicted\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJwwrWTw43rx"
      },
      "source": [
        "## 誤差の推移\n",
        "訓練データ、テストデータで誤差の推移をグラフ表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaJx4swE45XI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMrpac0m4Nct"
      },
      "source": [
        "滑らかに誤差が減少していることが確認できます。"
      ]
    }
  ]
}