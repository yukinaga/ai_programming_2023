{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_programming_2022/blob/main/06_generative_model/02_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74mqS_L8nq4"
      },
      "source": [
        "# VAEの実装\n",
        "VAEを実装します。  \n",
        "Encoderで手書き数字画像を潜在変数に圧縮した後、Decoderで元の画像を再構築します。  \n",
        "さらに、潜在変数が分布する潜在空間を可視化した上で、潜在変数を調整し生成画像の変化を確かめます。      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7h50pYSRaZ0"
      },
      "source": [
        "## 手書き文字画像\n",
        "今回は、VAEにより手書き文字画像を圧縮、復元します。  \n",
        "scikit-learnから、8×8の手書き数字の画像データを読み込んで表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9WCis8TGwx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "digits_data = datasets.load_digits()\n",
        "\n",
        "n_img = 10  # 表示する画像の数\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n_img):\n",
        "    # 入力画像\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(digits_data.data[i].reshape(8, 8), cmap=\"Greys_r\")\n",
        "    ax.get_xaxis().set_visible(False)  # 軸を非表示に\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "print(\"データの形状:\", digits_data.data.shape)\n",
        "print(\"ラベル:\", digits_data.target[:n_img])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtujqB1gSh4I"
      },
      "source": [
        "## 各設定\n",
        "画像の幅と高さが8ピクセルなので、入力層には8×8=64のニューロンが必要になります。  \n",
        "また、出力が入力を再現するように学習するので、出力層のニューロン数は入力層と同じになります。  \n",
        "今回は、潜在変数とラベルの関係を2次元で可視化するため、潜在変数の数は2とします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbSwlXZIUN7C"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -- 各設定値 --\n",
        "img_size = 8  # 画像の高さと幅\n",
        "n_in_out = img_size * img_size  # 入出力層のニューロン数\n",
        "n_mid = 16  # 中間層のニューロン数\n",
        "n_z = 2  # 潜在変数の数\n",
        "\n",
        "eta = 0.01  # 学習係数\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "interval = 10  # 経過の表示間隔\n",
        "\n",
        "# -- 訓練データ --\n",
        "digits_data = datasets.load_digits()\n",
        "x_train = np.asarray(digits_data.data)\n",
        "x_train /= 16  # 0-1の範囲に\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float)\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYb9yszSURKH"
      },
      "source": [
        "## モデルの構築\n",
        "PyTorchよりVAEのモデルを構築します。  \n",
        "Encoderの出力は、潜在変数の平均値$\\mu$および、標準偏差$\\sigma$の2乗（=分散）の対数とします。  \n",
        "   \n",
        "VAEのコードでは、バックプロパゲーションによる学習のためにReparametrization Trickが使われます。    \n",
        "平均値0標準偏差1のノイズεを発生させて、標準偏差$\\sigma$とかけて平均値$\\mu$に加えることで、潜在変数$z$とします。  \n",
        "$$\\epsilon \\sim N(0,\\, I)$$\n",
        "$$z=\\mu + \\epsilon\\odot\\sigma$$\n",
        "  \n",
        "損失関数は、以下で表されます。  \n",
        "\n",
        "$$E=E_{rec} + E_{reg}$$\n",
        "\n",
        "ここで、右辺第一項の再構成誤差$E_{rec}$は、出力と入力のずれを表します。  \n",
        "$$E_{rec} = \\frac{1}{h}\\sum_{i=1}^{h}\\sum_{j=1}^{m}\\left(-x_{ij}\\log y_{ij}-(1-x_{ij})log(1-y_{ij})\\right)$$\n",
        "$h$:バッチサイズ、￼$m$:入出力層のニューロン数、￼$x_{ij}$: VAEの入力、$y_{ij}$: VAEの出力   \n",
        "また、右辺第二項の正則化項$E_{reg}$は、平均値が0に、標準偏差が1に近づくように機能します。  \n",
        "$$E_{reg}=\\frac{1}{h}\\sum_{i=1}^{h}\\sum_{k=1}^{n}-\\frac{1}{2}(1+\\phi_{ik} - \\mu_{ik}^2 - exp(\\phi_{ik}))$$\n",
        "$h$:バッチサイズ、￼$n$:潜在変数の数、￼$\\mu_{ik}$: 平均値、$\\phi_{ik}$: 分散の対数   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfDQ8QJolyo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc_mid = nn.Linear(n_in_out, n_mid)  # Encoderの中間層\n",
        "        self.enc_mu = nn.Linear(n_mid, n_z)  # 平均値を求める層\n",
        "        self.enc_logvar = nn.Linear(n_mid, n_z)  # 分散のlogを求める層\n",
        "\n",
        "        self.dec_mid = nn.Linear(n_z, n_mid)  # Decoderの中間層\n",
        "        self.dec_out = nn.Linear(n_mid, n_in_out)  # Decoderの出力層\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encode(x)\n",
        "        y = self.decode(z)\n",
        "        return y\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = x.view(-1, n_in_out)  # バッチサイズ×入力の数\n",
        "\n",
        "        x = F.relu(self.enc_mid(x))\n",
        "        self.mu = self.enc_mu(x)\n",
        "        self.logvar = self.enc_logvar(x)\n",
        "\n",
        "        std = torch.exp(0.5*self.logvar)  # 標準偏差\n",
        "        eps = torch.randn_like(std)  # 正規分布に従う乱数\n",
        "        return self.mu + std*eps  # 潜在変数（reparametrization trick）\n",
        "\n",
        "    def decode(self, z):\n",
        "        x = F.relu(self.dec_mid(z))\n",
        "        x = F.sigmoid(self.dec_out(x))\n",
        "        return x\n",
        "\n",
        "    def loss(self, y, x):\n",
        "        x = x.view(-1, n_in_out)  # バッチサイズ×入力の数\n",
        "                                  \n",
        "        rec_loss = F.binary_cross_entropy(y, x, reduction=\"sum\")  # 再構成誤差\n",
        "        reg_loss = 0.5 * torch.sum(self.mu**2 + torch.exp(self.logvar)- self.logvar - 1)  # 正則化項\n",
        "        return (rec_loss, reg_loss)\n",
        "\n",
        "vae = VAE()\n",
        "vae.cuda()  # GPU対応\n",
        "print(vae)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC4f8NH6U86F"
      },
      "source": [
        "## 学習\n",
        "構築したVAEのモデルを使って、学習を行います。  \n",
        "入力を再現するように学習するので、正解は必要ありません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOAs3rh2PJJ"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Adam\n",
        "optimizer = optim.Adam(vae.parameters())\n",
        "\n",
        "# 損失のログ\n",
        "rec_error_record = []\n",
        "reg_error_record = []\n",
        "total_error_record = []\n",
        "\n",
        "# 学習\n",
        "for i in range(epochs):\n",
        "    vae.train()  # 訓練モード\n",
        "    loss_rec = 0\n",
        "    loss_reg = 0\n",
        "    loss_total = 0\n",
        "\n",
        "    for j, (x,) in enumerate(train_loader):  # ミニバッチ（x,）を取り出す\n",
        "        x = x.cuda()  # GPU対応\n",
        "        y = vae(x)\n",
        "        lrec, lreg = vae.loss(y, x)\n",
        "        loss = lrec + lreg\n",
        "        loss_rec += lrec.item()\n",
        "        loss_reg += lreg.item()\n",
        "        loss_total += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    loss_rec /= j+1\n",
        "    loss_reg /= j+1\n",
        "    loss_total /= j+1\n",
        "    rec_error_record.append(loss_rec)\n",
        "    reg_error_record.append(loss_reg)\n",
        "    total_error_record.append(loss_total)\n",
        "\n",
        "    if i%interval == 0:\n",
        "        print(\"Epoch:\", i, \"Loss_Rec:\", loss_rec, \"Loss_Reg:\", loss_reg, \"Loss_Total:\", loss_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2evU86Zb4Pd"
      },
      "source": [
        "## 誤差の推移\n",
        "記録された誤差の、推移を確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzuFBDy37tRg"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(rec_error_record)+1), rec_error_record, label=\"Rec_error\")\n",
        "plt.plot(range(1, len(reg_error_record)+1), reg_error_record, label=\"Reg_error\")\n",
        "plt.plot(range(1, len(total_error_record)+1), total_error_record, label=\"Total_error\")\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn-zFGCFWb3I"
      },
      "source": [
        "再構成誤差（Rec_error）と正則化項（Reg_error）が均衡し、全体の誤差（Total_error）が動かなくなることが確認できます。  \n",
        "潜在変数は範囲を広げることで入出力を一致させようとするのですが、これを正則化項が抑制していることになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dypLOxuaWhoE"
      },
      "source": [
        "## 潜在空間の可視化\n",
        "2つの潜在変数を平面にプロットし、潜在空間を可視化します。  \n",
        "入力画像はそれが何の数であるかを示すラベルとペアになっているので、このラベルを文字として潜在空間にプロットします。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVhJFHgTBffI"
      },
      "source": [
        "# 潜在変数を計算\n",
        "vae.eval()  # 評価モード\n",
        "x = x_train.cuda()\n",
        "z = vae.encode(x)  # 潜在変数\n",
        "z = z.cpu().detach().numpy()\n",
        "\n",
        "t = np.asarray(digits_data.target)  # ラベル\n",
        "\n",
        "# 潜在変数を平面にプロット\n",
        "plt.figure(figsize=(8, 8))\n",
        "for i in range(10):\n",
        "    zt = z[t==i]\n",
        "    z_1 = zt[:, 0]  # y軸\n",
        "    z_2 = zt[:, 1]  # x軸\n",
        "    marker = \"$\"+str(i)+\"$\"  # 数値をマーカーに\n",
        "    plt.scatter(z_2.tolist(), z_1.tolist(), marker=marker, s=75)\n",
        "\n",
        "plt.xlabel(\"z_2\")\n",
        "plt.ylabel(\"z_1\")\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-3, 3)\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qBV-ARLgwZi"
      },
      "source": [
        "各ラベルごとに、異なる潜在空間の領域が占められていることが確認できます。  \n",
        "このように、VAEは入力を潜在空間に割り当てるように学習します。  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P703G0wbz-Uo"
      },
      "source": [
        "### 画像の生成\n",
        "潜在変数を連続的に変化させて、生成される画像がどのように変化するのかを確かめます。  \n",
        "訓練済みVAEのDecoderを使って、画像を16×16枚生成します。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ua9MU4Rz-U1"
      },
      "source": [
        "# 画像の設定\n",
        "n_img = 16  # 画像を16x16並べる\n",
        "img_size_spaced = img_size + 2\n",
        "matrix_image = np.zeros((img_size_spaced*n_img, img_size_spaced*n_img))  # 全体の画像\n",
        "\n",
        "# 潜在変数\n",
        "z_1 = np.linspace(3, -3, n_img)  # 行\n",
        "z_2 = np.linspace(-3, 3, n_img)  # 列\n",
        "\n",
        "#  潜在変数を変化させて画像を生成\n",
        "for i, z1 in enumerate(z_1):\n",
        "    for j, z2 in enumerate(z_2):\n",
        "        z = torch.tensor([[z1, z2]], dtype=torch.float)\n",
        "        z = z.cuda()\n",
        "        y = vae.decode(z)  # Decoder\n",
        "        y = y.cpu().detach().numpy()\n",
        "        image = y.reshape(img_size, img_size)\n",
        "        top = i*img_size_spaced\n",
        "        left = j*img_size_spaced\n",
        "        matrix_image[top : top+img_size, left : left+img_size] = image\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(matrix_image.tolist(), cmap=\"Greys_r\")\n",
        "plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gmquBnv5ezZ"
      },
      "source": [
        "横軸、縦軸方向で潜在変数が変化していますが、それに伴う画像の変化が確認できます。  \n",
        "たった2つの潜在変数に、8×8の画像を圧縮できたことになります。  \n",
        "このように、データの特徴を少数の潜在変数に圧縮できて、潜在変数が生成データに与える影響が明瞭となるのがVAEの特徴です。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0qZ81oX3Bk"
      },
      "source": [
        "## 演習\n",
        "以下の式のように、再構成誤差（Rec_error）と正則化項（Reg_error）のバランスを、あえて崩してみましょう。  \n",
        "$$E=E_{rec} + \\alpha E_{reg}$$\n",
        "\n",
        "ここで、$\\alpha$は定数です。  \n",
        "\n",
        "コードの以下の箇所に注目します。\n",
        "```\n",
        "        loss = lrec + lreg\n",
        "```\n",
        "ここを例えば以下のように変更し、両者のバランスに変更を加えてください。\n",
        "```\n",
        "        alpha = 3.0\n",
        "        loss = lrec + alpha*lreg\n",
        "```\n",
        "これにより、結果がどのように変化するのか確かめてみましょう。  \n",
        "\n"
      ]
    }
  ]
}