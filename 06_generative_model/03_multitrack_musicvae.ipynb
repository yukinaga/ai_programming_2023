{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_programming_2022/blob/main/06_generative_model/03_multitrack_musicvae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkdg9jTjkTd"
      },
      "source": [
        "# MusicVAEによる作曲\n",
        "「MusicVAE」により、複数のトラックからなる曲を生成します。  \n",
        "生成には時間がかかるので、「編集」→「ノートブックの設定」→「ハードウェア アクセラレータ」で「GPU」を選択しておきましょう。  \n",
        "このノートブックのコードは、以下のリンク先のコードを参考にしています。  \n",
        "https://g.co/magenta/musicvae-colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPKARfZNZ_EA"
      },
      "source": [
        "## ライブラリのインストールとモデルのダウンロード\n",
        "Magentaと共に、音楽生成用のライブラリpyFluidSynth、MIDIデータを処理するためのpretty_midiなどをインストールします。  \n",
        "また、MusicVAEのモデルをダウンロードします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRTOCXhK9YAM"
      },
      "outputs": [],
      "source": [
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install -qU magenta\n",
        "\n",
        "!gsutil -q -m cp gs://download.magenta.tensorflow.org/models/music_vae/multitrack/* /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5-xG4QVx1iK"
      },
      "source": [
        "## ライブラリの導入\n",
        "Magentaの必要な機能と、NumPyなどのライブラリを導入します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuBbvFkNssM3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "from magenta.music.sequences_lib import concatenate_sequences\n",
        "\n",
        "import note_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XAYVxmpyLQb"
      },
      "source": [
        "## 各設定値\n",
        "曲の生成に関する各値を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YD3DbsM_rBP5"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4  # 一度に扱うデータ数\n",
        "Z_SIZE = 512  # 潜在変数の数\n",
        "TOTAL_STEPS = 512  # コードのベクトル化に使用\n",
        "CHORD_DEPTH = 49  # コードのベクトル化に使用\n",
        "SEQ_TIME = 2.0  # 各NoteSequenceの長さ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDC_l0Guz-go"
      },
      "source": [
        "## 関数の設定\n",
        "頻繁に行う処理を、関数にまとめておきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91UHtM2lrNvM"
      },
      "outputs": [],
      "source": [
        "def trim(seqs, seq_time=SEQ_TIME):  # NoteSequenceの長さを揃える\n",
        "    for i in range(len(seqs)):\n",
        "        seqs[i] = mm.extract_subsequence(seqs[i], 0.0, seq_time)\n",
        "        seqs[i].total_time = seq_time\n",
        "\n",
        "def encode_chord(chord):  # コードの文字列をベクトルに変換\n",
        "    index = mm.TriadChordOneHotEncoding().encode_event(chord)\n",
        "    encoded = np.zeros([TOTAL_STEPS, CHORD_DEPTH])\n",
        "    encoded[0,0] = 1.0\n",
        "    encoded[1:,index] = 1.0\n",
        "    return encoded\n",
        "\n",
        "def set_instruments(note_sequences):  # 楽器の調整\n",
        "    for i in range(len(note_sequences)):\n",
        "        for note in note_sequences[i].notes:\n",
        "            if note.is_drum:\n",
        "                note.instrument = 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4cnU3U75KJQ"
      },
      "source": [
        "## Conditionalではないモデル\n",
        "Conditionalではない、通常のVAEの学習済みモデルをチェックポイントとして読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w77rMbln5Q5K"
      },
      "outputs": [],
      "source": [
        "config = configs.CONFIG_MAP[\"hier-multiperf_vel_1bar_med\"]\n",
        "model = TrainedModel(\n",
        "    config,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    checkpoint_dir_or_path=\"/content/model_fb256.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1le8iM0PgLt"
      },
      "source": [
        "モデルからランダムに音声をサンプリングします。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBxRZjWO5VMH"
      },
      "outputs": [],
      "source": [
        "temperature = 0.2\n",
        "seqs = model.sample(n=BATCH_SIZE, length=TOTAL_STEPS, temperature=temperature)\n",
        "\n",
        "trim(seqs)\n",
        "for seq in seqs:\n",
        "    mm.play_sequence(seq, synth=mm.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxglQSRP2Ef"
      },
      "source": [
        "潜在変数から曲を生成します。  \n",
        "連続的に変化する潜在変数を、デコードしてつなげることにより曲を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWGL9Rn36E85"
      },
      "outputs": [],
      "source": [
        "num_bars = 32\n",
        "temperature = 0.2\n",
        "\n",
        "z1 = np.random.normal(size=[Z_SIZE])\n",
        "z2 = np.random.normal(size=[Z_SIZE])\n",
        "z = np.array([z1+z2*t for t in np.linspace(0, 1, num_bars)])  # z1とz2の間を線形補間\n",
        "\n",
        "seqs = model.decode(length=TOTAL_STEPS, z=z, temperature=temperature)\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y0BXztnDHep"
      },
      "source": [
        "`NoteSequence`をMIDIデータに変換し、保存してダウンロードします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V2HpDk9DHe2"
      },
      "outputs": [],
      "source": [
        "note_seq.sequence_proto_to_midi_file(seq, \"unconditional_vae.mid\")  #MIDI　データに変換し保存\n",
        "files.download(\"unconditional_vae.mid\")  # ダウンロード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJHzFw6Z0YRU"
      },
      "source": [
        "## Conditionalなモデル\n",
        "コードをラベルとしたConditional VAEのモデルを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3L9yw9Lqh8r"
      },
      "outputs": [],
      "source": [
        "config = configs.CONFIG_MAP[\"hier-multiperf_vel_1bar_med_chords\"]\n",
        "model = TrainedModel(\n",
        "    config,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    checkpoint_dir_or_path=\"/content/model_chords_fb64.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlih9njq1f4S"
      },
      "source": [
        "コードをラベルとして入力し、モデルからランダムに音声をサンプリングします。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziuRHiwyrUq4"
      },
      "outputs": [],
      "source": [
        "chord = \"C\"\n",
        "temperature = 0.2\n",
        "\n",
        "seqs = model.sample(n=BATCH_SIZE, length=TOTAL_STEPS, temperature=temperature,\n",
        "                    c_input=encode_chord(chord))\n",
        "\n",
        "for seq in seqs:\n",
        "    mm.play_sequence(seq, synth=mm.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e_Xw9ioSCtn"
      },
      "source": [
        "潜在変数から曲をデコードする際に、コードをラベルとして入力します。  \n",
        "これにより、そのコードをベースにした曲のNoteSeqenceを生成することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LxRc33frkw3"
      },
      "outputs": [],
      "source": [
        "chord_1 = \"C\"\n",
        "chord_2 = \"Caug\"\n",
        "chord_3 = \"Am\"\n",
        "chord_4 = \"E\"\n",
        "chords = [chord_1, chord_2, chord_3, chord_4]\n",
        "\n",
        "temperature = 0.2\n",
        "z = np.random.normal(size=[1, Z_SIZE])\n",
        "seqs = [\n",
        "    model.decode(length=TOTAL_STEPS,\n",
        "                 z=z,\n",
        "                 temperature=temperature,\n",
        "                 c_input=encode_chord(c))[0]\n",
        "    for c in chords\n",
        "]\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJDb3yWxTThS"
      },
      "source": [
        "潜在変数とベースとなるコード進行から曲を生成します。  \n",
        "連続的に変化する潜在変数を、コードとともにデコードしてつなげることにより曲を生成します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL3woZZywivE"
      },
      "outputs": [],
      "source": [
        "chord_1 = \"Dm\"\n",
        "chord_2 = \"F\"\n",
        "chord_3 = \"Am\"\n",
        "chord_4 = \"G\"\n",
        "chords = [chord_1, chord_2, chord_3, chord_4]\n",
        "\n",
        "num_bars = 32\n",
        "temperature = 0.2\n",
        "\n",
        "z1 = np.random.normal(size=[Z_SIZE])\n",
        "z2 = np.random.normal(size=[Z_SIZE])\n",
        "z = np.array([z1+z2*t for t in np.linspace(0, 1, num_bars)])  # z1とz2の間を線形補間\n",
        "\n",
        "seqs = [\n",
        "    model.decode(\n",
        "        length=TOTAL_STEPS,\n",
        "        z=z[i:i+1, :],\n",
        "        temperature=temperature,\n",
        "        c_input=encode_chord(chords[i%4])\n",
        "        )[0]\n",
        "    for i in range(num_bars)\n",
        "]\n",
        "\n",
        "trim(seqs)\n",
        "set_instruments(seqs)\n",
        "seq = concatenate_sequences(seqs)\n",
        "\n",
        "mm.plot_sequence(seq)\n",
        "mm.play_sequence(seq, synth=mm.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhtRBNNf05CA"
      },
      "source": [
        "`NoteSequence`をMIDIデータに変換し、保存してダウンロードします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcmmAToP4WE3"
      },
      "outputs": [],
      "source": [
        "note_seq.sequence_proto_to_midi_file(seq, \"conditional_vae.mid\")  #MIDI　データに変換し保存\n",
        "files.download(\"conditional_vae.mid\")  # ダウンロード"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMH/gkRuzMG3GvVsFHMN1AV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}