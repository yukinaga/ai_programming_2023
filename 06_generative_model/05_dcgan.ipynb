{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_programming_2022/blob/main/06_generative_model/05_dcgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74mqS_L8nq4"
      },
      "source": [
        "# DCGANの実装\n",
        "DCGANの実装を解説します。  \n",
        "DCGANでは、Discriminatorに畳み込みニューラルネットワーク（CNN）、GeneratorにCNNの逆を使用します。    \n",
        "GeneratorとDiscriminaorが均衡し、画像が生成されることを確かめましょう。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7h50pYSRaZ0"
      },
      "source": [
        "## 手書き文字画像\n",
        "DCGANに用いる訓練用のデータを用意します。    \n",
        "scikit-learnから、8×8の手書き数字の画像データを読み込んで表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9WCis8TGwx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "digits_data = datasets.load_digits()\n",
        "\n",
        "n_img = 10  # 表示する画像の数\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(n_img):\n",
        "    # 入力画像\n",
        "    ax = plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(digits_data.data[i].reshape(8, 8), cmap=\"Greys_r\")\n",
        "    ax.get_xaxis().set_visible(False)  # 軸を非表示に\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n",
        "print(\"データの形状:\", digits_data.data.shape)\n",
        "print(\"ラベル:\", digits_data.target[:n_img])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtujqB1gSh4I"
      },
      "source": [
        "## 各設定\n",
        "DCGANに必要な各設定を行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbSwlXZIUN7C"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# -- 各設定値 --\n",
        "img_size = 8  # 画像の高さと幅\n",
        "n_noise = 64  # ノイズの数\n",
        "\n",
        "eta = 0.001  # 学習係数\n",
        "epochs = 201  # 学習回数\n",
        "interval = 20  # 経過の表示間隔\n",
        "batch_size = 16\n",
        "\n",
        "# -- 訓練データ --\n",
        "digits_data = datasets.load_digits()\n",
        "x_train = np.asarray(digits_data.data)\n",
        "x_train = x_train / 16*2-1  # -1から1の範囲\n",
        "t_train = digits_data.target\n",
        "\n",
        "x_train = torch.tensor(x_train, dtype=torch.float)\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYb9yszSURKH"
      },
      "source": [
        "## Generatorの構築\n",
        "PyTorchによりGeneratorのモデルを構築します。  \n",
        "Generatorでは畳み込みの逆を行い、ノイズから画像を生成します。  \n",
        "今回は畳み込みの逆を行う層を3層重ねますが、この層は`ConvTranspose2d `により実装することができます。  \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfDQ8QJolyo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 画像サイズ 1x1→3x3\n",
        "        self.convt_1 = nn.ConvTranspose2d(n_noise, 64, 3)  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ\n",
        "        # 画像サイズ 3x3→5x5\n",
        "        self.convt_2 = nn.ConvTranspose2d(64, 32, 3)\n",
        "        # 画像サイズ 5x5→8x8\n",
        "        self.convt_3 = nn.ConvTranspose2d(32, 1, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, n_noise, 1, 1)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
        "        x = F.relu(self.convt_1(x))\n",
        "        x = F.relu(self.convt_2(x))\n",
        "        x = F.tanh(self.convt_3(x))\n",
        "        return x\n",
        "\n",
        "generator = Generator()\n",
        "generator.cuda()  # GPU対応\n",
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtA6l8bpD9rw"
      },
      "source": [
        "## Discriminatorの構築\n",
        "PyTorchによりDiscriminatorのモデルを構築します。   \n",
        "Discriminatorでは、畳込み層を3層重ねて画像の特徴を抽出します。  \n",
        "最後の層の活性化関数には、0から1までの値で本物かどうかを識別するためにsigmoid関数を使います。 \n",
        "   \n",
        "なお今回は、Generatorまで確実に逆伝播を行うために、活性化関数には入力が負でも0にならないLeakyReLUを使用します。  \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqGNtX2D97k"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 画像サイズ 8x8→5x5\n",
        "        self.conv_1 = nn.Conv2d(1, 16,  4)  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ\n",
        "        # 画像サイズ 5x5→3x3\n",
        "        self.conv_2 = nn.Conv2d(16, 32, 3)\n",
        "        # 画像サイズ 3x3→1x1\n",
        "        self.conv_3 = nn.Conv2d(32, 1, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1, img_size, img_size)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
        "        x = F.leaky_relu(self.conv_1(x), negative_slope=0.2)\n",
        "        x = F.leaky_relu(self.conv_2(x), negative_slope=0.2)\n",
        "        x = F.sigmoid(self.conv_3(x))\n",
        "        x = x.view(-1, 1)  # (バッチサイズ, 出力の数)\n",
        "        return x\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator.cuda()  # GPU対応\n",
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHM61pcsW6rY"
      },
      "source": [
        "### 画像の生成\n",
        "画像を生成して表示するための関数を定義します。  \n",
        "画像は、訓練済みのGenertorにノイズを入力することで生成されます。  \n",
        "画像は16×16枚生成されますが、並べて一枚の画像にした上で表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Waj3m0W-oo"
      },
      "source": [
        "# -- 画像を生成して表示 --\n",
        "def generate_images(i):\n",
        "    # 画像の生成\n",
        "    n_rows = 16  # 行数\n",
        "    n_cols = 16  # 列数\n",
        "    noise = torch.randn(n_rows * n_cols, n_noise).cuda()\n",
        "    g_imgs = generator(noise)\n",
        "    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n",
        "    g_imgs = g_imgs.cpu().detach().numpy()\n",
        "\n",
        "    img_size_spaced = img_size + 2\n",
        "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols))  # 全体の画像\n",
        "\n",
        "    #  生成された画像を並べて一枚の画像にする\n",
        "    for r in range(n_rows):\n",
        "        for c in range(n_cols):\n",
        "            g_img = g_imgs[r*n_cols + c].reshape(img_size, img_size)\n",
        "            top = r*img_size_spaced\n",
        "            left = c*img_size_spaced\n",
        "            matrix_image[top : top+img_size, left : left+img_size] = g_img\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(matrix_image.tolist(), cmap=\"Greys_r\", vmin=0.0, vmax=1.0)\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MA9y1jWPo0D"
      },
      "source": [
        "## 正解数の計算\n",
        "Discriminatorによる鑑定の正解数を、カウントする関数を定義します。  \n",
        "Discriminatorの精度の計算に使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUJa7_wP2gN"
      },
      "source": [
        "def count_correct(y, t):\n",
        "    correct = torch.sum((torch.where(y<0.5, 0, 1) ==  t).float())\n",
        "    return correct.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC4f8NH6U86F"
      },
      "source": [
        "## 学習\n",
        "構築したDCGANのモデルを使って、学習を行います。  \n",
        "Generatorが生成した画像には正解ラベル0、本物の画像には正解ラベル1を与えてDiscriminatorを訓練します。  \n",
        "その後にGeneratorを訓練しますが、この場合の正解ラベルは1になります。  \n",
        "これらの訓練を繰り返すことで、本物と見分けがつかない手書き文字画像が生成されるようになります。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOAs3rh2PJJ"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# 二値の交差エントロピー誤差関数\n",
        "loss_func = nn.BCELoss()\n",
        "\n",
        "# Adam\n",
        "optimizer_gen = optim.Adam(generator.parameters())\n",
        "optimizer_disc = optim.Adam(discriminator.parameters())\n",
        "\n",
        "# ログ\n",
        "error_record_fake = []  # 偽物画像の誤差記録\n",
        "acc_record_fake = []  # 偽物画像の精度記録\n",
        "error_record_real = []  # 本物画像の誤差記録\n",
        "acc_record_real = []  # 本物画像の精度記録\n",
        "\n",
        "# -- DCGANの学習 --\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "for i in range(epochs):\n",
        "    loss_fake = 0  # 誤差\n",
        "    correct_fake = 0  # 正解数\n",
        "    loss_real = 0\n",
        "    correct_real = 0\n",
        "    n_total = 0  # データの総数（精度の計算に使用）\n",
        "    for j, (x,) in enumerate(train_loader):  # ミニバッチ（x,）を取り出す\n",
        "\n",
        "        n_total += x.size()[0]  # バッチサイズを累積\n",
        "\n",
        "        # ノイズから画像を生成しDiscriminatorを訓練\n",
        "        noise = torch.randn(x.size()[0], n_noise).cuda()\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.zeros(x.size()[0], 1).cuda()  # 正解は0\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_fake += loss.item()\n",
        "        correct_fake += count_correct(y, t)\n",
        "\n",
        "        # 本物の画像を使ってDiscriminatorを訓練\n",
        "        imgs_real= x.cuda()\n",
        "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_real)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_real += loss.item()\n",
        "        correct_real += count_correct(y, t)\n",
        "\n",
        "        # Generatorを訓練\n",
        "        noise = torch.randn(x.size()[0]*2, n_noise).cuda()  # バッチサイズを2倍にする\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.ones(x.size()[0]*2, 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_gen.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_gen.step()  # Generatorのみパラメータを更新\n",
        "\n",
        "    loss_fake /= j+1  # 誤差\n",
        "    error_record_fake.append(loss_fake)\n",
        "    acc_fake = correct_fake / n_total  # 精度\n",
        "    acc_record_fake.append(acc_fake)\n",
        "\n",
        "    loss_real /= j+1  # 誤差\n",
        "    error_record_real.append(loss_real)\n",
        "    acc_real = correct_real / n_total  # 精度\n",
        "    acc_record_real.append(acc_real)\n",
        "\n",
        "    # 一定間隔で誤差と精度、および生成された画像を表示\n",
        "    if i % interval == 0:\n",
        "        print (\"Epochs:\", i)\n",
        "        print (\"Error_fake:\", loss_fake , \"Acc_fake:\", acc_fake)\n",
        "        print (\"Error_real:\", loss_real , \"Acc_real:\", acc_real)\n",
        "        generate_images(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aleBcXwqgGq"
      },
      "source": [
        "学習が進むにつれて、次第に明瞭な手書き数字画像が形作られていきます。  \n",
        "GeneratorはDiscriminatorをうまく騙せるように、DiscriminatorはGeneratorに騙されないように、互いに切磋琢磨した結果、本物に近い画像が生成されるようになりました。      \n",
        "なお、学習がうまく進まない場合もあるので、そのような場合は学習を最初からやり直してみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxNus-jNWk3"
      },
      "source": [
        "### 誤差と正解率の推移\n",
        "学習中における、誤差と正解率の推移を確認します。  \n",
        "Discriminatorに本物画像を鑑定させた際の誤差の推移と、偽物画像を鑑定させた際の誤差の推移をグラフに表示します。  \n",
        "正解率の推移も表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIKYIQODJ0Q"
      },
      "source": [
        "# -- 誤差の推移 --\n",
        "plt.plot(range(len(error_record_fake)), error_record_fake, label=\"Error_fake\")\n",
        "plt.plot(range(len(error_record_real)), error_record_real, label=\"Error_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()\n",
        "\n",
        "# -- 正解率の推移 --\n",
        "plt.plot(range(len(acc_record_fake)), acc_record_fake, label=\"Acc_fake\")\n",
        "plt.plot(range(len(acc_record_real)), acc_record_real, label=\"Acc_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KvTaPccn5nm"
      },
      "source": [
        "DCGANの場合でも、GeneratorとDiscriminatorが競合するように学習し、その結果生じた均衡のなかで、少しずつ本物らしい画像が形作られていくことが分かります。  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0qZ81oX3Bk"
      },
      "source": [
        "## 演習\n",
        "ノイズの数が生成する画像に与える影響を確かめてみましょう。  \n",
        "\n",
        "コードの以下の箇所に注目します。\n",
        "```\n",
        "# -- 各設定値 --\n",
        "img_size = 8  # 画像の高さと幅\n",
        "n_noise = 16  # ノイズの数\n",
        "```\n",
        "ここを、例えば以下のように変更しましょう。\n",
        "```\n",
        "# -- 各設定値 --\n",
        "img_size = 8  # 画像の高さと幅\n",
        "n_noise = 4  # ノイズの数\n",
        "```\n",
        "これにより、生成される画像がどのように変化するのか確かめてみましょう。  \n",
        "\n"
      ]
    }
  ]
}