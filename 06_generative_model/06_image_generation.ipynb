{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cr0qZ81oX3Bk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/ai_programming_2022/blob/main/06_generative_model/06_image_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74mqS_L8nq4"
      },
      "source": [
        "# LSGANによる画像素材の生成\n",
        "LSGANにより、128x128の画像素材を生成します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TzTU3cUSp4_"
      },
      "source": [
        "## データの読み込み\n",
        "多数の犬猫画像が格納された、Pet Datasetをダウンロードし、解凍します。  \n",
        "https://www.robots.ox.ac.uk/~vgg/data/pets/  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h7BA67Ed5wT"
      },
      "source": [
        "!wget https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz -P ./data  # ダウンロード\n",
        "!tar -zxvf ./data/images.tar.gz -C ./data  # 解凍"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7h50pYSRaZ0"
      },
      "source": [
        "## 各設定\n",
        "LSGANに必要な各設定を行います。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9WCis8TGwx"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "img_size = 128  # 入力画像の高さと幅\n",
        "n_noise = 64  # ノイズの数\n",
        "\n",
        "epochs = 1200 # 学習回数\n",
        "interval = 20  # 経過の表示間隔\n",
        "batch_size = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # transforms.Resize((img_size, img_size)),  # サイズの変更\n",
        "    transforms.CenterCrop(256),  # 画像の中央を取り出し\n",
        "    transforms.RandomCrop(128),  # ランダムに切り抜き\n",
        "    transforms.RandomHorizontalFlip(),  # ランダムに左右反転\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # -1から1の範囲に\n",
        "])\n",
        "\n",
        "# データセットの設定\n",
        "pets_datasets = datasets.ImageFolder(\n",
        "    root= \"./data\", \n",
        "    transform=transform\n",
        "    )\n",
        "print(\"画像の枚数:\", len(pets_datasets))\n",
        "\n",
        "# DataLoaderの設定\n",
        "train_loader = DataLoader(pets_datasets, \n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                           num_workers=2\n",
        "                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPdix5iqTntg"
      },
      "source": [
        "## 画像データの確認\n",
        "画像データを並べて表示し、確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgIQOsQZI2ab"
      },
      "source": [
        "image = next(iter(train_loader))[0]\n",
        "image = image.cpu().detach().numpy().transpose(0, 2, 3, 1)  # (バッチ、行、列、チャンネル)に変更\n",
        "image = image/2+0.5  # 0-1の範囲に\n",
        "\n",
        "rows = 3  # 行数\n",
        "columns = 5  # 列数\n",
        "scale = 4  # 表示スケール\n",
        "plt.figure(figsize=(scale*columns, scale*rows))\n",
        "\n",
        "for i in range(rows*columns):\n",
        "    ax = plt.subplot(rows, columns, i+1)\n",
        "    plt.imshow(image[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYb9yszSURKH"
      },
      "source": [
        "## Generatorの構築\n",
        "PyTorchによりGeneratorのモデルを構築します。  \n",
        "Generatorでは畳み込みの逆を行い、ノイズから画像を生成します。  \n",
        "今回は畳み込みの逆を行う層を6層重ねます。また、途中でデータが偏らないようにBatch Normalizationを導入します。  \n",
        "これらは、`ModuleList`により学習可能な層としてリストに格納します。  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qfDQ8QJolyo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.layers = nn.ModuleList([\n",
        "            # 画像サイズ 1x1→4x4\n",
        "            nn.ConvTranspose2d(n_noise, 512, 4, 1, 0),  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ、ストライド、パディング\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            # 画像サイズ 4x4→8x8\n",
        "            nn.ConvTranspose2d(512, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            # 画像サイズ 8x8→16x16\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # 画像サイズ 16x16→32x32\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "           # 画像サイズ 32x32→64x64\n",
        "            nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            # 画像サイズ 64x64→128x128\n",
        "            nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
        "            nn.Tanh(),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, n_noise, 1, 1)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "generator = Generator()\n",
        "generator.cuda()  # GPU対応\n",
        "print(generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtA6l8bpD9rw"
      },
      "source": [
        "## Discriminatorの構築\n",
        "Discriminatorのモデルを構築します。   \n",
        "今回は畳み込みを行う層を6層重ねます。また、途中でデータが偏らないようにBatch Normalizationを導入します。  \n",
        "LSGANでは、最後の層の活性化関数にはsigmoid関数ではなく恒等関数を使います。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKqGNtX2D97k"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            # 画像サイズ 128x128→64x64\n",
        "            nn.Conv2d(3, 32, 4, 2, 1),  # 入力のチャンネル数, 出力のチャンネル数, カーネルのサイズ\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # 画像サイズ 64x64→32x32\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # 画像サイズ 32x32→16x16\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # 画像サイズ 16x16→8x8\n",
        "            nn.Conv2d(128, 256, 4, 2, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "           # 画像サイズ 8x8→4x4\n",
        "            nn.Conv2d(256, 512, 4, 2, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "            # 画像サイズ 4x4→1x1\n",
        "            nn.Conv2d(512, 1, 4, 1, 0),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, img_size, img_size)  # (バッチサイズ, チャンネル数, 高さ, 幅)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = x.view(-1, 1)  # (バッチサイズ, 出力の数)\n",
        "        return x\n",
        "\n",
        "discriminator = Discriminator()\n",
        "discriminator.cuda()  # GPU対応\n",
        "print(discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHM61pcsW6rY"
      },
      "source": [
        "### 画像の生成\n",
        "画像を生成して表示するための関数を定義します。  \n",
        "画像は、訓練済みのGenertorにノイズを入力することで生成されます。  \n",
        "画像は4×4枚生成されますが、並べて一枚の画像にした上で表示されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Waj3m0W-oo"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -- 画像を生成して表示 --\n",
        "def generate_images(i):\n",
        "    # 画像の生成\n",
        "    n_rows = 4  # 行数\n",
        "    n_cols = 4  # 列数\n",
        "    noise = torch.randn(n_rows * n_cols, n_noise).cuda()\n",
        "    g_imgs = generator(noise)\n",
        "    g_imgs = g_imgs/2 + 0.5  # 0-1の範囲にする\n",
        "    g_imgs = g_imgs.cpu().detach().numpy()\n",
        "\n",
        "    img_size_spaced = img_size + 2\n",
        "    matrix_image = np.zeros((img_size_spaced*n_rows, img_size_spaced*n_cols, 3))  # 全体の画像\n",
        "\n",
        "    #  生成された画像を並べて一枚の画像にする\n",
        "    for r in range(n_rows):\n",
        "        for c in range(n_cols):\n",
        "            g_img = g_imgs[r*n_cols + c].transpose(1, 2, 0).reshape(img_size, img_size, 3)\n",
        "            top = r*img_size_spaced\n",
        "            left = c*img_size_spaced\n",
        "            matrix_image[top : top+img_size, left : left+img_size, :] = g_img\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(matrix_image, vmin=0.0, vmax=1.0)\n",
        "    plt.tick_params(labelbottom=False, labelleft=False, bottom=False, left=False)  # 軸目盛りのラベルと線を消す\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MA9y1jWPo0D"
      },
      "source": [
        "## 正解数の計算\n",
        "Discriminatorによる鑑定の正解数を、カウントする関数を定義します。  \n",
        "Discriminatorの精度の計算に使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUJa7_wP2gN"
      },
      "source": [
        "def count_correct(y, t):\n",
        "    correct = torch.sum((torch.where(y<0.5, 0, 1) ==  t).float())\n",
        "    return correct.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC4f8NH6U86F"
      },
      "source": [
        "## 学習\n",
        "構築したLSGANのモデルを使って、学習を行います。  \n",
        "Generatorが生成した画像には正解ラベル0、本物の画像には正解ラベル1を与えてDiscriminatorを訓練します。  \n",
        "その後にGeneratorを訓練しますが、この場合の正解ラベルは1になります。  \n",
        "LSGANでは、誤差に二乗誤差を使用します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoOAs3rh2PJJ"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# 平均二乗誤差\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "# Adam\n",
        "optimizer_gen = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=1e-5)\n",
        "optimizer_disc = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=1e-5)\n",
        "\n",
        "# ログ\n",
        "error_record_fake = []  # 偽物画像の誤差記録\n",
        "acc_record_fake = []  # 偽物画像の精度記録\n",
        "error_record_real = []  # 本物画像の誤差記録\n",
        "acc_record_real = []  # 本物画像の精度記録\n",
        "\n",
        "# -- DCGANの学習 --\n",
        "generator.train()\n",
        "discriminator.train()\n",
        "for i in range(epochs):\n",
        "    loss_fake = 0  # 誤差\n",
        "    correct_fake = 0  # 正解数\n",
        "    loss_real = 0\n",
        "    correct_real = 0\n",
        "    n_total = 0  # データの総数（精度の計算に使用）\n",
        "    for j, (x, t) in enumerate(train_loader):  # ミニバッチ（x,）を取り出す\n",
        "\n",
        "        n_total += x.size()[0]  # バッチサイズを累積\n",
        "\n",
        "        # ノイズから画像を生成しDiscriminatorを訓練\n",
        "        noise = torch.randn(x.size()[0], n_noise).cuda()\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.zeros(x.size()[0], 1).cuda()  # 正解は0\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_fake += loss.item()\n",
        "        correct_fake += count_correct(y, t)\n",
        "\n",
        "        # 本物の画像を使ってDiscriminatorを訓練\n",
        "        imgs_real= x.cuda()\n",
        "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_real)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_disc.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_disc.step()  # Discriminatorのみパラメータを更新\n",
        "        loss_real += loss.item()\n",
        "        correct_real += count_correct(y, t)\n",
        "\n",
        "        # Generatorを訓練\n",
        "        imgs_fake = generator(noise)  # 画像の生成\n",
        "        t = torch.ones(x.size()[0], 1).cuda()  # 正解は1\n",
        "        y = discriminator(imgs_fake)\n",
        "        loss = loss_func(y, t)\n",
        "        optimizer_gen.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer_gen.step()  # Generatorのみパラメータを更新\n",
        "\n",
        "    loss_fake /= j+1  # 誤差\n",
        "    error_record_fake.append(loss_fake)\n",
        "    acc_fake = correct_fake / n_total  # 精度\n",
        "    acc_record_fake.append(acc_fake)\n",
        "\n",
        "    loss_real /= j+1  # 誤差\n",
        "    error_record_real.append(loss_real)\n",
        "    acc_real = correct_real / n_total  # 精度\n",
        "    acc_record_real.append(acc_real)\n",
        "\n",
        "    # 一定間隔で誤差と精度、および生成された画像を表示\n",
        "    if i % interval == 0:\n",
        "        print (\"Epochs:\", i)\n",
        "        print (\"Error_fake:\", loss_fake , \"Acc_fake:\", acc_fake)\n",
        "        print (\"Error_real:\", loss_real , \"Acc_real:\", acc_real)\n",
        "        generate_images(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvxNus-jNWk3"
      },
      "source": [
        "### 誤差と正解率の推移\n",
        "学習中における、誤差と正解率の推移を確認します。  \n",
        "Discriminatorに本物画像を鑑定させた際の誤差の推移と、偽物画像を鑑定させた際の誤差の推移をグラフに表示します。  \n",
        "正解率の推移も表示します。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIKYIQODJ0Q"
      },
      "source": [
        "# -- 誤差の推移 --\n",
        "plt.plot(range(len(error_record_fake)), error_record_fake, label=\"Error_fake\")\n",
        "plt.plot(range(len(error_record_real)), error_record_real, label=\"Error_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.show()\n",
        "\n",
        "# -- 正解率の推移 --\n",
        "plt.plot(range(len(acc_record_fake)), acc_record_fake, label=\"Acc_fake\")\n",
        "plt.plot(range(len(acc_record_real)), acc_record_real, label=\"Acc_real\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr0qZ81oX3Bk"
      },
      "source": [
        "## 演習\n",
        "他の画像データセットを使って学習を行い、本物らしい画像が生成されることを確認しましょう。  \n",
        "参考:\n",
        "* Large-scale CelebFaces Attributes (CelebA) Dataset  \n",
        "http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
        "* Flickr Logos dataset  \n",
        "http://image.ntua.gr/iva/datasets/flickr_logos/\n",
        "* DAGM 2007  \n",
        "https://conferences.mpi-inf.mpg.de/dagm/2007/prizes.html  \n",
        "* etc…\n"
      ]
    }
  ]
}